# pytorch-lightning-smoke-detection

Created: 2021 Anshuman Dewangan

This repository uses [Pytorch Lightning](https://www.pytorchlightning.ai/) for wildfire smoke detection.

# Setup & Usage
## Initial Setup
1. Clone directory:
```bash
git clone https://gitlab.nrp-nautilus.io/anshumand/pytorch-lightning-smoke-detection.git
cd pytorch-lightning-smoke-detection
```

2. Edit torch-gpu.yaml to replace instances of "anshumand" to <your_username>

## Usage
1. Create Kubernetes container: ```kubectl create -f torch-gpu.yaml```
2. Confirm pod is running: ```kubectl get pods```
3. Forward port to local machine: ```kubectl port-forward deployment/torch-gpu-anshumand 8888:8888```
4. Open Jupyter Lab on browser (password = ```digits```): ```http://127.0.0.1:8888/```
5. (Optional) To SSH into virtual server from local terminal, use: ```kubectl exec -it deployment/torch-gpu-anshumand -- /bin/bash```
6. (Optional) If Jupyter Lab server goes down for some reason, restart it with: ```jupyter lab --port=8888 --no-browser --ip=0.0.0.0 --allow-root --NotebookApp.password="$(echo digits | python3 -c 'from notebook.auth import passwd;print(passwd(input()))')"  --ContentsManager.allow_hidden=True```

# Documentation

## Kubernetes
**Relevant Files:**
- ```Dockerfile```: Code that is run when the container is set up. Uses nvidia/cuda module as base. Installs system packages and necessary Python packages. Starts Jupyter Lab server at port 8888
- ```torch-gpu.yaml```: Parameters with which the container is initialized
- ```.gitlab-ci.yml```: YAML file that allows CI/CD with GitLab to automatically build new container with Dockerfile changes


## Data Setup
**Relevant Files:**
- ```generate_batched_tiled_data.py```: Takes raw images and labels and generates a dataset that tiles images and batches them per image. Generates metadata.pkl. **WARNING:** takes ~1 hour and 250GB of storage for the full dataset
- ```/userdata/kerasData/data/new_data/batched_tiled_data/metadata.pkl```: Generated by generate_batched_tiled_data.py. See full info below.
- ```batched_tiled_dataloader.py```: Includes datamodule and dataloader for dataset generated by generate_batched_tiled_data.py for training

**Relevant Directories:**
- ```/userdata/kerasData/data/new_data/raw_images```: location of raw images
- ```/userdata/kerasData/data/new_data/drive_clone```: location of labels
- ```/userdata/kerasData/data/new_data/batched_tiled_data```: location of generated data from generate_batched_tiled_data.py that is tiled & batched

**metadata.pkl:**

metadata.pkl is a dictionary generated by generate_batched_tiled_data.py that includes helpful information about the files. Params:
- raw_images_path (str): path to raw images
- labels_path (str): path to XML labels
- output_path (str): desired path of outputted Numpy files
- image_dimensions (int, int): dimensions original image should be resized to
- tile_dimensions (int, int): desired dimensions of tiles
- overlap_amount (int): how much the tiles should overlap in pixels
- smoke_threshold (int): how many pixels of smoke to label tile as a positive sample? 
- time_created (datetime): date & time of when the dataset was created
- fire_to_images (dict): dictionary with fires as keys and list of corresponding images as values
- num_fires (int): total number of fires in dataset
- num_images (int): total number of images in dataset
- ground_truth_label (dict): dictionary with fires as keys and 1 if fire has "+" in its file name
- has_xml_label (dict): dictionary with fires as keys and 1 if fire has a .xml file associated with it
- has_positive_tile (dict): dictionary with fires as keys and 1 if at least one tiled image has a label of 1


## Training
