"""
Created by: Anshuman Dewangan
Date: 2021

Description: Loads tiled & batched data that was generated from generate_batched_tiled_data.py
"""

import pytorch_lightning as pl
import pickle
from torch.utils.data.dataset import Dataset
from torch.utils.data import DataLoader
from pathlib import Path
import numpy as np
from sklearn.model_selection import train_test_split

from generate_batched_tiled_data import save_batched_tiled_images


class BatchedTiledDataModule(pl.LightningDataModule):
    def __init__(self, 
                 data_path='./data/', 
                 metadata_path='./data/metadata.pkl', 
                 batch_size=1, 
                 series_length=5, 
                 time_range=(-2400, 2400), 
                 prepare_data=False,
                 generate_data_params=None,
                 delete_generated_data=False):
        """
        Args:
            - data_path (str): path to batched_tiled_data
            - metadata_path (str): path to metadata.pkl file generated by generate_batched_tiled_data.py. Usually data_path/metadata.pkl
            - batch_size (int): batch_size for training
            - series_length (int): how many sequential images should be used for training
            - time_range (int, int): The time range of images to consider for training by time stamp. Should be between -2400 and 2400 and divisible by 60
            - prepare_data (bool): if generate_batched_tiled_data.py should be run to generate the batched & tiled dataset. 
                WARNING: will take ~1 hour and 250 GB of storage for full dataset
            - generate_data_params (dict): params to generate the data. Must include:
                - raw_images_path (str): path to raw images
                - labels_path (str): path to XML labels
                - output_path (str): desired path of outputted Numpy files
                - image_dimensions (int, int): dimensions original image should be resized to
                - tile_dimensions (int, int): desired dimensions of tiles
                - overlap_amount (int): how much the tiles should overlap in pixels
                - smoke_threshold (int): how many pixels of smoke to label tile as a positive sample? 
        """
        super().__init__()
        self.data_path = data_path
        self.metadata = pickle.load(open(metadata_path, 'rb'))
        
        self.prepare_data = prepare_data
        self.generate_data_params = generate_data_params
        
        self.batch_size = batch_size
        self.series_length = series_length
        
        # Confirm time_range is between -2400 and 2400 and divisible by 60
        assert time_range[0] % 60 == 0 and time_range[0] >= -2400 and time_range[0] <= 2400-60
        assert time_range[1] % 60 == 0 and time_range[1] >= -2400+60 and time_range[1] <= 2400
        self.time_range = time_range

    def prepare_data(self):
        # Generates batched & tiled data
        # WARNING: will take ~1 hour and 250 GB of storage for full dataset
        if self.prepare_data:
            save_batched_tiled_images(
                raw_images_path=self.generate_data_params['raw_images_path'], 
                labels_path=self.generate_data_params['labels_path'], 
                output_path=self.generate_data_params['output_path'], 
                image_dimensions=self.generate_data_params['image_dimensions'], 
                tile_dimensions=self.generate_data_params['tile_dimensions'], 
                overlap_amount=self.generate_data_params['overlap_amount'], 
                smoke_threshold=self.generate_data_params['smoke_threshold'])
        
    def setup(self, stage=None):
        # Create train, val, test split of *fires*
        train_fires, val_fires = train_test_split(list(self.metadata['fire_to_images'].keys()), test_size=0.4)
        val_fires, test_fires = train_test_split(val_fires, test_size=0.5)
        
        # Calculate indices related to desired time frame
        time_range_lower_idx = int((self.time_range[0] + 2400) / 60)
        time_range_upper_idx = int((self.time_range[1] + 2400) / 60) + 1 

        # Create dictionary to store series_length of images
        self.metadata['image_series'] = {}
        
        # Shorten fire_to_images to relevant time frame
        for fire in train_fires:
            self.metadata['fire_to_images'][fire] = self.metadata['fire_to_images'][fire][time_range_lower_idx:time_range_upper_idx]
                    
        # Add series_length of images to image_series for each image
        for fire in self.metadata['fire_to_images']:
            for i, img in enumerate(self.metadata['fire_to_images'][fire]):
                self.metadata['image_series'][img] = []
                idx = i
                
                while (len(self.metadata['image_series'][img]) < self.series_length):
                    self.metadata['image_series'][img].append(self.metadata['fire_to_images'][fire][idx])
                    if idx != 0: idx -= 1
        
        # Generate splits using actual images for each fire
        self.train_split = [image for image in self.metadata['fire_to_images'][fire] for fire in train_fires]
        self.val_split   = [image for image in self.metadata['fire_to_images'][fire] for fire in val_fires]
        self.test_split  = [image for image in self.metadata['fire_to_images'][fire] for fire in test_fires]

    def train_dataloader(self):
        train_dataset = BatchedTiledDataloader(self.data_path, self.train_split, self.metadata)
        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)
        return train_loader

    def val_dataloader(self):
        val_dataset = BatchedTiledDataloader(self.data_path, self.val_split, self.metadata)
        val_loader = DataLoader(val_dataset, batch_size=self.batch_size)
        return val_loader

    def test_dataloader(self):
        test_dataset = BatchedTiledDataloader(self.data_path, self.test_split, self.metadata)
        test_loader = DataLoader(test_dataset, batch_size=self.batch_size)
        return test_loader

    
class BatchedTiledDataloader(Dataset):
    def __init__(self, data_path, data_split, metadata):
        """
        Args:
            - data_path (str): path to batched_tiled_data
            - data_split (list): list of images of the current split
            - metadata (dict): metadata dictionary from DataModule
        """
        self.data_path = Path(data_path)
        self.data_split = data_split
        self.metadata = metadata

    def __len__(self):
        return len(self.data_split)

    def __getitem__(self, idx):
        cur_image = self.data_split[idx]
        
        # Load all pixel inputs of each image in the series
        x = []
        for file_name in self.metadata['image_series'][cur_image]:
            x.append(np.load(self.data_path/f'{file_name}_img.npy'))

        # x.shape = [num_tiles, series_length, num_channels, height, width]
        # e.g. [108, 5, 3, 224, 224]
        x = np.transpose(np.stack(x), (1, 0, 2, 3, 4))/255 
        
        # Load tile-level labels for current image
        # y.shape = [num_tiles] e.g. [108,]
        y = np.load(self.data_path/f'{cur_image}_lbl.npy') 

        # Load image-level labels for current image
        ground_truth_label = self.metadata['ground_truth_label'][cur_image]
        has_xml_label = self.metadata['has_xml_label'][cur_image]
        has_positive_tile = self.metadata['has_positive_tile'][cur_image]
        
        return x, y, ground_truth_label, has_xml_label, has_positive_tile