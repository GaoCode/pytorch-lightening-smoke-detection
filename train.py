# Torch & related imports
import torch
from torch import nn
from torch.nn import functional as F
import pytorch_lightning as pl
from pytorch_lightning.callbacks.early_stopping import EarlyStopping
from torch.optim.lr_scheduler import ReduceLROnPlateau
import torchvision
import torchmetrics

# Other package imports
import pickle
import numpy as np
from argparse import ArgumentParser
import pdb # for debugging

# File imports
from batched_tiled_dataloader import BatchedTiledDataModule, BatchedTiledDataloader
import metric_utils


#####################
## Argument Parser
#####################

parser = ArgumentParser(description='Takes raw wildfire images and saves tiled images')

# Path args
parser.add_argument('--data-path', type=str, default='/userdata/kerasData/data/new_data/batched_tiled_data',
                    help='Path to batched & tiled data.')
parser.add_argument('--metadata-path', type=str, default='/userdata/kerasData/data/new_data/batched_tiled_data/metadata.pkl',
                    help='Path to metadata.pkl generated by generate_batched_tiled_data.py.')
parser.add_argument('--omit-images-path', type=str, default=None,
                    help='Path to omit_images.npy containing list of images that are incorrectly labeled.')
parser.add_argument('--train-split-path', type=str, default=None,
                    help='(Optional) Path to txt file with train image paths. Only works if train, val, and test paths are provided.')
parser.add_argument('--val-split-path', type=str, default=None,
                    help='(Optional) Path to txt file with val image paths. Only works if train, val, and test paths are provided.')
parser.add_argument('--test-split-path', type=str, default=None,
                    help='(Optional) Path to txt file with test image paths. Only works if train, val, and test paths are provided.')

# Dataloader args
parser.add_argument('--batch-size', type=int, default=1,
                    help='Batch size for training.')
parser.add_argument('--num-workers', type=int, default=0,
                    help='Number of workers for dataloader.')
parser.add_argument('--series-length', type=int, default=1,
                    help='Number of sequential video frames to process during training.')
parser.add_argument('--time-range-min', type=int, default=-2400,
                    help='Start time of fire images to consider during training. ')
parser.add_argument('--time-range-max', type=int, default=2400,
                    help='End time of fire images to consider during training (inclusive).')

# Model args
parser.add_argument('--learning-rate', type=float, default=0.001,
                    help='Learning rate for training.')
parser.add_argument('--no-lr-schedule', action='store_true',
                    help='Disables ReduceLROnPlateau learning rate scheduler. See PyTorch Lightning docs for more details.')
parser.add_argument('--no-freeze-backbone', action='store_true',
                    help='Disables freezing of layers on pre-trained backbone.')

# Training args
parser.add_argument('--min-epochs', type=int, default=10,
                    help='Min number of epochs to train for.')
parser.add_argument('--max-epochs', type=int, default=50,
                    help='Max number of epochs to train for.')
parser.add_argument('--no-auto-lr-find', action='store_true',
                    help='Disables auto learning rate finder. See PyTorch Lightning docs for more details.')
parser.add_argument('--no-early-stopping', action='store_true',
                    help='Disables early stopping based on validation loss. See PyTorch Lightning docs for more details.')
parser.add_argument('--no-sixteen-bit', action='store_true',
                    help='Disables use of 16-bit training to reduce memory. See PyTorch Lightning docs for more details.')
parser.add_argument('--no-stochastic-weight-avg', action='store_true',
                    help='Disables stochastic weight averaging. See PyTorch Lightning docs for more details.')
parser.add_argument('--gradient-clip-val', type=float, default=0.5,
                    help='Clips gradients to prevent vanishing or exploding gradients. See PyTorch Lightning docs for more details.')
parser.add_argument('--accumulate-grad-batches', type=int, default=16,
                    help='Accumulate multiple batches before calling loss.backward() to increase effective batch size. See PyTorch Lightning docs for more details.')


#####################
## Model
#####################

class LightningModel(pl.LightningModule):

    def __init__(self, learning_rate=0.001, lr_schedule=True, freeze_backbone=True):
        super().__init__()
        
        # Initialize model
        resnet = torchvision.models.resnet50(pretrained=True)
        resnet.fc = nn.Identity()
        
        if freeze_backbone:
            for param in resnet.parameters():
                param.requires_grad = False
        
        self.conv = resnet
        
        self.fc1 = nn.Linear(in_features=2048, out_features=512)
        self.fc2 = nn.Linear(in_features=512, out_features=64)
        self.fc3 = nn.Linear(in_features=64, out_features=1)
        
        # Initialize model params
        self.criterion = nn.BCEWithLogitsLoss()
        self.learning_rate = learning_rate
        self.lr_schedule = lr_schedule        
        
        # Initialize evaluation metrics
        self.metrics = {}
        self.metric_splits = ['train/', 'val/', 'test/']
        self.metric_titles = ['tile_', 'image-gt_', 'image-xml_', 'image-pos-tile_']
        self.metric_labels = ['accuracy', 'precision', 'recall', 'f1']
        self.metric_functions = [torchmetrics.Accuracy, torchmetrics.Precision, torchmetrics.Recall, torchmetrics.F1]
        
        for split in self.metric_splits:
            for title in self.metric_titles:
                for label, func in zip(self.metric_labels, self.metric_functions):
                    self.metrics[split+title+label] = func(mdmc_average='global') if title == self.metric_titles[0] else func()
        
    def forward(self, x):
        x = x.float()
        batch_size, num_tiles, series_length, num_channels, height, width = x.size()
        
        x = x.view(batch_size * num_tiles, num_channels * series_length, height, width)
        x = self.conv(x) # [batch_size * num_tiles * series_length, 2048]
        
        x = x.view(batch_size, num_tiles, -1) # [batch_size, num_tiles, 2048]
        x = F.relu(self.fc1(x)) # [batch_size, num_tiles, 512]
        x = F.relu(self.fc2(x)) # [batch_size, num_tiles, 64]
        x = self.fc3(x) # [batch_size, num_tiles, 1]
        
        return x
        
    def step(self, batch, split):
        x, tile_labels, ground_truth_labels, has_xml_labels, has_positive_tiles = batch
        
        # Compute loss
        output = self.forward(x).squeeze(dim=2) # [batch_size, num_tiles]
        loss = self.criterion(output, tile_labels)
        
        # Compute predictions
        tile_preds = metric_utils.predict_tile(output)
        image_preds = metric_utils.predict_image_from_tile_preds(tile_preds)
        
        # Compute metrics
        for label in self.metric_labels:
            self.metrics[split+self.metric_titles[0]+label].to(self.device)(tile_preds, tile_labels.int())
            self.metrics[split+self.metric_titles[1]+label].to(self.device)(image_preds, ground_truth_labels)
            self.metrics[split+self.metric_titles[2]+label].to(self.device)(image_preds, has_xml_labels)
            self.metrics[split+self.metric_titles[3]+label].to(self.device)(image_preds, has_positive_tiles)
            
        # Log metrics
        self.log(split+'loss', loss, on_step=(split==self.metric_splits[0]),on_epoch=True)
        
        for title in self.metric_titles:
            for label in self.metric_labels:
                name = split+title+label
                self.log(name, self.metrics[name], on_step=False, on_epoch=True)
        
        return loss
        
    def training_step(self, batch, batch_idx):
        return self.step(batch, self.metric_splits[0])

    def validation_step(self, batch, batch_idx):
        self.step(batch, self.metric_splits[1])

    def test_step(self, batch, batch_idx):
        self.step(batch, self.metric_splits[2])

    def configure_optimizers(self):
        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)
        
        if self.lr_schedule:
            scheduler = ReduceLROnPlateau(optimizer)
            return {"optimizer": optimizer, 
                    "lr_scheduler": scheduler, 
                    "monitor": "val_loss"}
        else:
            return optimizer

    
#####################
## Main
#####################
    
def main(# Path args
        data_path, 
        metadata_path, 
        omit_images_path=None, 
        train_split_path=None, 
        val_split_path=None, 
        test_split_path=None,

        # Dataloader args
        batch_size=1, 
        num_workers=0, 
        series_length=1, 
        time_range=(-2400,2400), 

        # Model args
        learning_rate=0.001,
        lr_schedule=True,
        freeze_backbone=True,

        # Trainer args 
        min_epochs=10,
        max_epochs=50,
        auto_lr_find=True,
        early_stopping=True,
        sixteen_bit=True,
        stochastic_weight_avg=True,
        gradient_clip_val=0,
        accumulate_grad_batches=1):
    
    # Initialize data_module
    data_module = BatchedTiledDataModule(
        # Path args
        data_path=data_path,
        metadata_path=metadata_path,
        train_split_path=train_split_path,
        val_split_path=val_split_path,
        test_split_path=test_split_path,
        
        # Dataloader args
        batch_size=batch_size,
        num_workers=num_workers,
        series_length=series_length,
        time_range=time_range)
    
    # Initialize model
    model = LightningModel(learning_rate=learning_rate,
                           lr_schedule=lr_schedule,
                           freeze_backbone=freeze_backbone)

    # Implement EarlyStopping
    early_stop_callback = EarlyStopping(
       monitor='val_loss',
       min_delta=0.00,
       patience=5,
       verbose=False,
       mode='max')

    # Initialize a trainer
    trainer = pl.Trainer(
        # Trainer args
        min_epochs=min_epochs,
        max_epochs=max_epochs,
        auto_lr_find=auto_lr_find,
        callbacks=[early_stop_callback] if early_stopping else None,
        precision=16 if sixteen_bit else 32,
        stochastic_weight_avg=stochastic_weight_avg,
        gradient_clip_val=gradient_clip_val,
        accumulate_grad_batches=accumulate_grad_batches,
        
        # Dev args
#         fast_dev_run=True, 
        overfit_batches=5,
        log_every_n_steps=1,
#         track_grad_norm=2,
#         weights_summary='full',
#         profiler="simple", # "advanced" "pytorch"
#         log_gpu_memory=True,
        gpus=1)
    
    # Auto find learning rate
    if auto_lr_find:
        trainer.tune(model)
        
    # Train the model
    trainer.fit(model, data_module)
    
    # Evaluate the best model on the test set
    trainer.test(model, data_module)

    
if __name__ == '__main__':
    args = parser.parse_args()
        
    main(# Path args
        data_path=args.data_path, 
        metadata_path=args.metadata_path, 
        omit_images_path=args.omit_images_path, 
        train_split_path=args.train_split_path, 
        val_split_path=args.val_split_path, 
        test_split_path=args.test_split_path,

        # Dataloader args
        batch_size=args.batch_size, 
        num_workers=args.num_workers, 
        series_length=args.series_length, 
        time_range=(args.time_range_min,args.time_range_max), 

        # Model args
        learning_rate=args.learning_rate,
        lr_schedule=not args.no_lr_schedule,
        freeze_backbone=not args.no_freeze_backbone,

        # Trainer args
        min_epochs=args.min_epochs,
        max_epochs=args.max_epochs,
        auto_lr_find=not args.no_auto_lr_find,
        early_stopping=not args.no_early_stopping,
        sixteen_bit=not args.no_sixteen_bit,
        stochastic_weight_avg=not args.no_stochastic_weight_avg,
        gradient_clip_val=args.gradient_clip_val,
        accumulate_grad_batches=args.accumulate_grad_batches)